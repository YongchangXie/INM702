{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485529a3",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pandas as pd\n",
    "import torchvision.datasets as datasets\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09293b50",
   "metadata": {},
   "source": [
    "# Dataset Loading & Processing\n",
    "\n",
    "Load dataset and split the data into training set and validation set. DataLoader in torch.utils are used for loading therequired data bypassing various parameters, (e.g. batch size).\n",
    "Referenced: https://www.kaggle.com/lonnieqin/cifar10-image-classification-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66af6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = DataLoader(datasets.CIFAR10(\"data\", train=True, transform=transform, download=True), batch_size=batch_size)\n",
    "valid_ds = DataLoader(datasets.CIFAR10(\"data\", train=False, transform=transform, download=True), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecccf8b6",
   "metadata": {},
   "source": [
    "# Implement Neural Networks\n",
    "Apply a simple neural network by PyTorch for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6799ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a regular neural network for classfication \n",
    "class Neural_Network():\n",
    "    def __init__(self):\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Dropout(),                           # implement Dropuout \n",
    "            nn.Linear(256 * 6 * 6, 1024),            # Input size is equal to number of output from final convolution time the size of average pooling\n",
    "            nn.ReLU(),                              # Apply ReLu activation funciton\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 512),                   # the input to the linear funcntion is the output from last layer\n",
    "            nn.ReLU(),                               # Apply ReLu activation funciton\n",
    "            nn.Linear(512, 10)             # get the final output with the size same as target value \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd76758",
   "metadata": {},
   "source": [
    "##### Improvements for Neural Networkds( Convolution NN & Dropout) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d42987",
   "metadata": {},
   "source": [
    "The Convolutional Neural Networks have three important Layers\n",
    "- Convolutional Layer : Used to extract features from the image.\n",
    "- Pooling Layer : The main goal of this layer is to reduce the convoluted size of the feature map and to reduce Computational costs.\n",
    "- Activation Functions : These are used to learn and approximate any kind of continuous and complex relations between variables of the network.\n",
    "\n",
    "\n",
    "Dropout is applied to improvce generalization error and reduce overfitting problem.\n",
    "\n",
    "\n",
    "Referecnes:\n",
    "- https://www.kaggle.com/lonnieqin/cifar10-image-classification-with-pytorch\n",
    "-https://www.analyticsvidhya.com/blog/2021/09/convolutional-neural-network-pytorch-implementation-on-cifar10-dataset/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c25c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, no_class):\n",
    "        super(CNN, self).__init__()                  # Setting the initial parameter\n",
    "        self.convolution = nn.Sequential(                           # Import Neural Network module from torch\n",
    "# Define first 2D convolution layer\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=2),     # Applies a 2D convolution form input image\n",
    "            # create 3 channels in the import image, as 3 direct to the colored image and in RBG format and produce 64 output chanel by Convolution, \n",
    "            # the size of convolving kernel is 3 with replicate padding mode\n",
    "            nn.ReLU(),                                      # Apply ReLu activation funciton\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),          # Applies a 2D max pooling over an input signal composed of several input planes.\n",
    "# Define Second 2D convolution layer            \n",
    "            nn.Conv2d(64, 128, kernel_size=5, padding=2),         # Applies a 2D convolution over an input signal composed of several input planes.\n",
    "           # the input size is same as the previous convolution output, the output size is set to be 2 times larger \n",
    "            nn.ReLU(),                                           # Apply ReLu activation funciton\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "# Define Third 2D convolution layer            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),                                        \n",
    "# Define Fourth 2D convolution layer \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),                                       \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.average_pool = nn.AdaptiveAvgPool2d((6, 6))         # To creat a average pooling to input signal from several input planes  \n",
    "        \n",
    "        # apply a classifier to faltten the layer to bulid a linear layer to map the values to 10 target values\n",
    "        # Which is help to determine the class\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),                           # implement Dropuout \n",
    "            nn.Linear(256 * 6 * 6, 1024),            # Input size is equal to number of output from final convolution time the size of average pooling\n",
    "            nn.ReLU(),                              # Apply ReLu activation funciton\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 512),                   # the input to the linear funcntion is the output from last layer\n",
    "            nn.ReLU(),                               # Apply ReLu activation funciton\n",
    "            nn.Linear(512, no_class)             # get the final output with the size same as target value \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):                 # Define the forward, where x is the input image\n",
    "        x = self.convolution(x)              # calculate the convolution of input image\n",
    "        x = self.average_pool(x)                # average the polling from output of convolution\n",
    "        x = torch.flatten(x, start_dim =1)            # faltten the output of average poiling to array\n",
    "        x = self.classifier(x)                       # Using normal neural network to calculate the output where input is from convolution \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272e1de",
   "metadata": {},
   "source": [
    "Implement final model for Convolution Neural Network to this machine learning problme which have 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8862ecd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(no_class=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e594e2",
   "metadata": {},
   "source": [
    "# Training \n",
    "Create a basic step to train the CNN been build and to get the required output. For loop is created for iterate the mode over each epoch. The progressing using CPU for each batch are setted. The backward function is requied to add in each iteration in order to update optimum parameter values.\n",
    "Reference:\n",
    "- https://www.analyticsvidhya.com/blog/2021/09/convolutional-neural-network-pytorch-implementation-on-cifar10-dataset/\n",
    "- https://www.kaggle.com/lonnieqin/cifar10-image-classification-with-pytorch\n",
    "- https://d2l.ai/chapter_computer-vision/kaggle-cifar10.html\n",
    "- https://www.cs.toronto.edu/~lczhang/aps360_20191/lec/w03/convnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba089665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: [Training] 1523.95s/7944.84s\n"
     ]
    }
   ],
   "source": [
    "# Define a funciton to disply the the results of training and testing \n",
    "# Code Reference: https://www.kaggle.com/samanemami/convolutional-nn-cifar10-79-acc-138-sec\n",
    "def display_resultes(message, metrics):\n",
    "    display.clear_output(wait=False) \n",
    "    if len(metrics[\"loss\"]) > 0:\n",
    "        pd.DataFrame(metrics).plot()   \n",
    "        plt.show()\n",
    "    print(message)\n",
    "\n",
    "epochs = 10\n",
    "train_steps = len(train_data)\n",
    "valid_steps = len(validation_data)\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate=0.001)        # input a Adam optimizer with learnign rate 0.001\n",
    "loss_CEL = torch.nn.CrossEntropyLoss()                                  # Input cross entropy loss function for loss calculation\n",
    "metrics = {\"loss\": [], \"val_loss\": [], \"val_accuracy\": []}             # Create a matrix to store loss, validation loss and validation accuracy\n",
    "device = torch.device(\"cpu\")                                          # Selecting CPU to do the calculation\n",
    "model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []           # Create a marray to store the resultes of train loss\n",
    "    valid_losses = []           # Create a marray to store the resultes of validation loss      \n",
    "    model.train()               \n",
    "\n",
    "# Developing a for loop iteration to train the dataset\n",
    "    for batch in train_data:\n",
    "        inputs, targets = batch              \n",
    "        inputs = inputs.to(device)         # using cpu to import input value\n",
    "        targets = targets.to(device)       # using cpu to import target label\n",
    "        output = model(inputs)             # using the input value from training set and CNN to calculate results \n",
    "        loss = loss_CEL(output, targets)  # calculate the loss between predict value and target value\n",
    "        train_losses.append(loss.data.item())  # Store the train loss into the dataframe\n",
    "        loss.backward()                    # apply backward funciton to loss, in order to find the gradient of output values and parameters  \n",
    "        optimizer.step()                   #  performs a parameter update based on the current gradient and the update rule \n",
    "        optimizer.zero_grad()               # call the optimizer.zero_grad to store the gradient of each parameter after backward function\n",
    "        \n",
    "\n",
    "# Developing a for loop iteration to test the dataset\n",
    "    no_correct = 0\n",
    "    no_samples = 0\n",
    "    for batch in validation_data:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)          # using cpu to import input value\n",
    "        targets = targets.to(device)        # using cpu to import target label\n",
    "        output = model(inputs)             # using the input value from validation set and CNN to calculate results \n",
    "        loss = loss_CEL(output, targets)     # calculate the loss between predict value and target value\n",
    "        valid_losses.append(loss.data.item())    # Store the testing loss into the dataframe\n",
    "        \n",
    "        correct_prediciton = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)   # input softmax function to determining the accurancy of the prediction\n",
    "        no_correct += torch.sum(correct_prediciton).item()       # calculate all the number of correct prediction\n",
    "        no_samples += correct_prediciton.shape[0]                # number of sample  \n",
    "\n",
    "# Evaluation to the CNN performance \n",
    "    train_loss = torch.mean(torch.Tensor(train_losses)).item()   # function to add up the trainig loss and store the value into matrix \n",
    "    valid_loss = torch.mean(torch.Tensor(valid_losses)).item()   # function to add up the validation loss and store the value into matrix \n",
    "    accuracy = no_correct / no_samples if no_samples > 0 else 0    # function to calculate overall performance of CNN\n",
    "    metrics[\"loss\"].append(train_loss)                       # store all the loss value into blank matrix created before\n",
    "    metrics[\"val_loss\"].append(valid_loss)                 # store all the validation loss value into blank matrix created before\n",
    "    metrics[\"val_accuracy\"].append(accuracy)                # store all the accuracy value into blank matrix created before\n",
    "    display.clear_output(wait=False) \n",
    "    pd.DataFrame(metrics).plot()                            # plot the results \n",
    "    plt.show()\n",
    "    display_resultes(\n",
    "        \"Training Loss: %.2f Validation Loss: %.2f accuracy: %.2f\" %(train_loss, valid_loss, accuracy), \n",
    "        metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1dbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61589c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
